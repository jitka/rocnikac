\chapter{Algorithms and enhancements}

\section{Overview of algorithms}

\subsection{Meta algorithm}

\TODO{hrana (u,v)}

We will describe a~meta algorithm how to prove that a finite two-player
positional game is determined, that is there is a~winning strategy for the first
player or draw strategy for the second.

All game states can be represented as a~rooted tree. Each game position is a
node and if someone can turn from one position to another, there is an edge
between the corresponding nodes. We will not try to build a~complete game tree,
representing every possible position in the game, because it would be too large
to be represented in memory. Instead, we will incrementally build a partial game 
tree starting from the empty tree, trying to keep the partial game tree as small as
possible.

We assign to each node one of three possible values -- \value{true},
\value{false}, \value{unknown}. Node will have value \value{true} when we prove
that there is a~winning strategy for the first player and value \value{false}
when we prove that there is a~draw strategy for the second player. Otherwise
the node has value \value{unknown}. We say that node is solved if it has value
\value{true} or \value{false}.

The algorithm starts with one node with value \value{unknown}. In each iteration the
algorithm does one of the two things:

\begin{itemize} 
	\item{Develop node} We choose one leaf node with value \value{unknown}
		and develop it, which means that we create its sons. When 
		a son is created we evaluate it (we check whether one of the players
		won).
	\item{Update node} We choose one developed node with value \value{unknown}
		and look over its sons. We check if we can assign value \value{true} 
		or \value{false} to the node.
\end{itemize}

Algorithm ends when root is solved and so game is determined.

There are two types of nodes. When the first player is on turn it is an \node{or}
node. To assign value \value{true} for it, it is enough if one of its sons
have value \value{true}. Then, the first player has a winning strategy which starts by the
turn to the node with value \value{true}. On the other hand, when the first player has
no winning strategy after any turn he has no winning strategy at all. So we can
assign value \value{false} when all sons have value \value{false}. If none of above holds
the value of the node remains \value{unknown}. Hence value of an \node{or} node can be found by
an operation which is very similar to simple logical \fce{or}.

The second type of node is an \node{and} node. The second player is on turn. Assigning values
works in a similar way, we just use \fce{and}-like operation instead of \fce{or}-like.

\obr{obrazek 1) and kolecko} 

\subsection{Depth-first search} We can use ordinary depth-first search for
searching the complete game tree and solving the root.  We start by creating
the root. We develop root and choose one of it sons. We solve the son
recursively and update the root. We continue solving the sons and updating
until the root is solved.

This algorithm is a suitable solution for the clique game. The depth of the
tree is $N \choose 2$ so it doesn't take much memory. This is obviously slow
but if we use some of enhancements of pn-search which are described later, this
algorithm can find a solution for $N=5$ and maybe more.

\subsection{Alpha-beta}

Alpha-beta is a well known algorithm for finding good strategies. \TODO{citace}.
We can use it for any node $n$. It searches a part of the subtree under $n$ and for
nodes in some depth uses a rating function and returns the rating of $n$. The rating
which alpha-beta returns can be used for deciding to which position to turn. It
is useful as a~heuristic and can be used for example in AI and also in our
problem. We can use depth-first search and when we make a decision which sons
to solve, we first rate all its sons by alpha-beta and then solve them in order
determined by the ratings.

\subsection{PN-search}

PN-search was introduced by Allis \TODO{citace}. We will describe an immediate evaluation
variant of it which is better suited for our problem, because a test if a position is winning is
is quick.

PN-search is a~best-first search. We need to specify which node is the best for our problem.
 We start with some definitions, which were used in \TODO{allis}. 

\newtheorem*{prove}{Definition}	
\begin{prove}
We will say that we \emph{prove} a node if we proved that the first player has winning strategy
from it and we can assign \value{true} to it. 
\end{prove}

\newtheorem*{disprove}{Definition}	
\begin{disprove}
We will say that we \emph{disprove} node if we proved that the second player has draw strategy
from it and we can assign \value{false} to it. 
\end{disprove}

\newtheorem*{proofSet}{Definition}	
\begin{proofSet}
	For any partial game tree $T$ a~set of leaf nodes with value \value{unknown} $S$ is a~{\sl proof set}
	if proving all nodes within $S$ proves $T$.
\end{proofSet}

\newtheorem*{disproofSet}{Definition}	
\begin{disproofSet}
	For any partial game tree $T$ a~set of leaf nodes with value \value{unknown} $S$ is a~{\sl disproof set}
	if disproving all nodes within $S$ disproves $T$.
\end{disproofSet}

\newtheorem*{proofNumber}{Definition} 
\begin{proofNumber}
	For any partial game tree $T$, the {\sl proof number} of $T$ is defined as the 
	cardinality of the smallest proof set of $T$.
\end{proofNumber}

\newtheorem*{disproofNumber}{Definition}	
\begin{disproofNumber}
	For any partial game tree $T$, the {\sl disproof number} of $T$ is defined as the 
	cardinality of the smallest disproof set of $T$.
\end{disproofNumber}

We will show how proof and disproof numbers work and how they can be calculated
on some examples. At picture \obr{2)} you can see a tree with proof numbers.
Nodes with value \value{true} have proof number 0 --- there is nothing left to
prove. Nodes with value \value{false} have proof number $ \infty $ --- there
exists no set of nodes which proves it. Leaf nodes with value \value{unknown}
have proof number 1 because it is enough to prove the node itself. Internal
\node{and} node has proof number which is equal to sum of the proof numbers of
its sons, because for proving the \node{and} node we must prove all its sons by
proving their proof sets. Internal \node{or} node has proof number equal to
minimum of proof numbers of it sons because we need to prove at least one of
its son.

Determining the disproof number works in a similar way. As you can see an picture
\obr{3)}. 

\newtheorem*{mostProvingNode}{Definition}	
\begin{mostProvingNode}
	For any partial game tree $T$ a~{\sl most proving node} of $T$ is a~node, which by 
	obtaining the value \value{true} reduces $T$'s proof number by 1, while by obtaining the
	value \value{false} reduces $T$'s disproof number by 1.
\end{mostProvingNode}

Most-proving node is a node which helps solve the root in both cases (proving or disproving it)
so we will use 
it as the best node in best-first search. We will show that such a node exists in every
partial tree.

\newtheorem{mpnExist}{Theorem}
\begin{mpnExist}
	In every partial game tree there is a most proving node.
\end{mpnExist}

\begin{proof}

	We will prove it by induction on depth of partial game tree.
	It is enough to show that there is a minimal proof set and a minimal disproof set having a 
	common node. Proving the node reduces the proof set and disproving it reduces the
	disproof set.

	\begin{itemize} 
		\item{Basic} 
			If root is a~leaf node, both the proving and the disproving set 
			contain just the root.
		\item{Induction step}
			Let the root be an \node{and} node. Minimal proof set of the root is the minimal proof set
			of its son $s$ with minimal proof number. Minimal disproof set of the root
			is the union of minimal disproof sets of its sons, so it contains
			the minimal disproof set of $s$.

			Imagine a~game (sub)tree where $s$ is root. By induction, his
			minimal proof set and minimal disproof set have a common node, which is also 
			in the intersection of minimal proof and minimal disproof sets of the original root and
			is the most proving node.

			Proof for \node{or} root proceeds analogously.
	\end{itemize}
\end{proof}

Now we informally describe the whole pn-search, as detailed in pseudocode in
\TODO{pseudkod}. 

We store a partial game tree and proof and disproof numbers of each node. We
start with one node --- the root. Then we repeat the following three steps
until the root is solved. 

The first step is \fce{selectMostProving(node)}. This function works similarly
to the proof that a most proving node exists. \obr{4)obrazek} We start in the
root and continue by choosing the son which has the minimal proof number when
we are in \node{and} node, respectively the minimal  disprove number in
\node{or} node, until we are in a~leaf node. When there are more sons with a
minimal number we choose the leftmost one (we fix an arbitrary ordering). 

The second step is \fce{developNode(mostProvingNode)}. There we create sons of
the \fce{mostProvingNode} and evaluate them.

The third step is \fce{updateAncestors(mostProvingNode)}. Proof and disproof
numbers in partial game tree have changed so we must update their stored
values. We start updating \fce{mostProvingNode} and continue by updating its
ancestors up to the root. At the end of these three steps the (dis)proof numbers
are again correct, because only numbers above \fce{mostProvingNode} could have
changed.

\TODO{opsat pseudokod z allis}

\subsection{Choice of algorithm}

\TODO{prepsat}
ze tetusim jestli je vyhr/prohr u nejakych nahodnych nodu
We choose pn-search to our problem. It seems to be quicker then alpha-beta. \TODO{citace} Alpha-beta
could be part of pn-search when we use rating from it as a~heuristic (\TODO{11}, \ref{ord}).
And finally there are many enhancements and heuristics which seem to help reduce the partial game tree size  
then the choice the algorithm.

\section{Enhancements of PN-search}

\TODO{obecny kec ze to
	dela prakticky jine algoritmy 
	a ze muze byt problem s kombinovanim,
	ze vetsina byla v allise at nemusim citovat furt,
ze pd-numbers MPN nejsou podle definice
ze to aplikuju hlavne na ten zakladny
ze tady hlavne predstavuju jak funguji neresim jak moc pomuzou
}

\subsection{Path from root}

Proof number search is best-first search. Its disadvantage is that searching for most-proving node takes
a lot of time. 

\newtheorem*{currentPath}{Definition}	
\begin{currentPath}
	A~{\sl current path} is a~path from root to the most proving node which is
	used when we search most proving node. \TODO{ktera cesta}
\end{currentPath}

In pn-search each iteration starts at the root and descends down. After developing
most proving node we update proof and disproof numbers starting in most-proving and 
return the way back into root. So we traverse the current path twice. 

There are two enhancements which reduce the number of nodes traversed to select the
most proving node. 

\subsubsection{Last changed node} \label{last}

We make two basic observations.
\begin{itemize}
\item When there is no change during node update, traversal can be stop even though we
aren't at root.
\item Current paths of two consecutive iterations have the same beginning. They can differ
only in part where proof or disproof number was updated.
\end{itemize}

\newtheorem*{currentNode}{Definition}	
\begin{currentNode}
A~{\sl current node} is a~node from current path. It is the lowest unchanged node or
root if everything was changed.
\end{currentNode}

Enhanced pn-search works like ordinary pn-search. It has one variable
called $currentNode$, at the beginning value of $currentNode$ is root. Each
$selectMostProvingNode()$ starts in $currentNode$. And each $updateAncestors()$
ends at the node where proof and disproof numbers haven't been changed and sets 
$currentNode$ to the last changed node. You can see as it works there. \obr{(5))}

\subsubsection{DF-PN search} \label{dfpn}

We can save even more traversing. In two consecutive iterations current paths
have common beginning. \obr{6.1)} We reduced the part when proof and disproof
numbers stay same. Now it's time to reduce part when they are changing and work
as in \obr{6.2b)}. We need to know the highest node which will not be in new
current path. We use thresholds for it --- we will store two new numbers for
each node on the current path. They will be set so that when (dis)proof number
will be smaller than its threshold we stay in the same subtree. If its equal or
bigger we must either update also its parent or the son with minimal (dis)proof
number will by different. 

Let $p$ and $d$ be proof and disproof number of node $n$. Let $pt$ and $dt$ be
their thresholds. When $n$ is \node{and} node we assume that its sons $1\ldots k$
are ordered so $p_1 < p_2 < \ldots < p_k$. Rules for setting new thresholds
were deduced in \TODO{cit: epsilon trick str4}:\obr{6.3)} 
\begin{eqnarray*} 
	pt_1 = min(pt, p_2+1), dt_1 = dt - d + d_1.
\end{eqnarray*}

When $n$ is \node{or} node we assume that $d_1 < d_2 < \ldots < d_k$. Rules
are symmetrical:  
\begin{eqnarray*} 
	pt_1 = pt-p+p_1, dt_1 = min(dt,d_2+1).
\end{eqnarray*}

When we delay updateAncestors to the time when $p > pt$ or $d > dt$ we can make
another changes. 

Main point is that we don't need to store whole partial game three. It is
enough to store nodes from current path. Algorithm could be implemented
recursively (but we didn't done it) and for this reason it is called depth-first.
It isn't typical depth-first search because one node can be visited more
then once \TODO{je tu potreba priklid nebo to je videt?}. 

DP-PN search is typically implemented with cache used for storing as many
nodes from partial game tree as possible. 

\subsection{Transpositions in DAG} \label{DAG}
 
As we see in picture \obr{8) 3 obr,neco jen ... misto hran, nespojene, spojene
jen poradi, spojene i symetrie popisek..} of chess tree we are exploring one
game state many times. Basic enhancement is to join that nodes into one.

The problem is that we have game DAG \footnote{There aren't cycles because in a
positional game all edges leads into position with more positions occupied.}
instead of game tree and proof and disproof numbers cannot by computed like
above because one node can increase proof number of another node more than by
one \obr{7)obr Proof and disproof numbers a) by definition --- disproof set for
root are three undeveloped nodes b) computed as
above}. However $proofNumbers$ and $disproofNumbers$ computed by
PN-search can be useful even though they can be higher then proof and disproof
number as they was defined. 

We can use PN-search with a~few modifications. When we generate children we
check whether they already exist. We can use hash table for this. Second
modification is that we need to update all parents. This could cause problems
if used together with other enhancements as last changed node \ref{last} but if
we use ordinary PN-search it works. Allis proof it in \cite{allis} (page
39--40).

One game state in turn $t$ can be visited in the worst case $t!$ times because
positions can be occupied in any order. So joining them is a~good idea and
there exist many enhancements of this enhancement.

In this thesis we will try to use advantage of symmetry as much as possible.
So we want in addition join game positions which are isomorph. See \obr{9) }
how it works on tic-tac-toe game tree. However in clique game we cannot join
all isomorphuos game position into one because finding \TODO{jak
se to pise?} represent is hard problem. So we will use ``almost
representative graph'' \TODO{novy nazev} instead. See section \ref{norm}
for definition.

\textbf{Note}: We will use ``game tree'' even if we talk about game DAG. It can be little confusing 
but in many cases there isn't any reason to distinguish if we talk about tree or DAG. 
We will use ``leaf node'' when we are talking about undeveloped node. 

%\subsection{Heuristic 1 1}
%%
%\TOD{napsat co je me?}
%
%By definition the proof and disproof numbers of a~leaf node with value
%\value{unknown} are 1 and 1. In general and/or tree we don't now anything more
%and we must use this assignment, when we know more we can set these numbers
%differently and break definition.
%
%The way the algorithm proceeds can seems similar to breath-first search when we run it
%on some tree where up to some depth initially all nodes have value \value{unknown}
%and each node on same level has same number of sons. \ODO{obrazek vyvoj}
%
%For this reason it is useful to initially set proof and disproof numbers
%differently. The first we can use the numbers which the node will probably have if
%we develop it. For example if the \node{and} node has $n$ sons we give it proof
%number $n$ and disproof number $1$.
%
%We will call this enhancement $n 1$. It causes the algorithm will develop left most
%nodes until it finds some node with value \value{true} or \value{false}. \ODO{obrazek}
%
%\ODO{!!!!!!!!!!!!!!!!!!!!je tohle dobre? ? myslim ze je}
%There is other way how to assign the numbers. \ODO{citace} When PN-search works on partial
%tree where are only few or no value \value{true} and \value{false} nodes, it prefers node with 
%fewer sons. We can initially set $n$ using some heuristic. When it is \node{and} node with
%$n$ sons and position is good for the first player we give it numbers $m 1$ ($m$ is slightly less
%then $n$). When it is \node{or} node with $n$ sons and position is bad for the first player we
%give it numbers $1 m$ ($m$ is slightly more then $n$).

\subsection{Weak PN-search} \label{weak}

When we use transposition into DAG one node can by counted in (dis)proof number many times.
Hence we show an enhancement which tries to minimize this disadvantage. 

\TODO{tady mam v kodu nejakou vyjimku to je pro 0 nebo pro 1?}
\TODO{zkontrolovat ze je tam ta \^2 jen jednou}
\TODO{da se to cele nejak jednoduse vysvetlit? \^2.. kdyz vyvracim zalezi na branching factor kdyz dokazuju prehodit}
We will count proof and disproof number in a~different way:
\begin{enumerate} 
	\item Let $n$ be a~leaf node. It depends on value of node.
		\begin{itemize}
			\item \value{true} $p(n)=0$, $d(n)=\infty$
			\item \value{false} $p(n)=\infty$, $d(n)=0$
			\item \value{unknown} $p(n)=1$, $d(n)=1$
		\end{itemize}
	\item Let $n$ be an internal \node{or} node with $k$ sons. Then \newline
		$p(n) = min_{1 \le i \le k}(n_i)$, \newline
		$d(n) = max_{1 \le i \le k}(n_i) + (k-1)^2$. 
	\item Let $n$ be an internal \node{and} node with $k$ sons. Then \newline
		$p(n) = max_{1 \le i \le k}(n_i) + (k-1)$, \newline 
		$d(n) = min_{1 \le i \le k}(n_i)$.
\end{enumerate}
		
\subsection{Deleting solved subtrees} \label{delete}

To save memory we can delete node after it is solved. However this doesn't 
help --- see \TODO{4.kapitola}

\subsection{ Prohrano pokud neni vyhravajici linie} \label{nofreeK4}
\TODO{dopsat az po prvni kapitole}

\subsection{PN-set}
\TODO{dopsat az napragramuju}

\subsection{1+\TODO{epsilon} trick}
\TODO{dopsat az napragramuju}


\TODO{tady mozna PN2, DB}

